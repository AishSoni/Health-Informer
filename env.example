# =============================================================================
# HEALTH INFORMER - Environment Variables
# =============================================================================
# Copy this file to .env.local and configure your settings

# =============================================================================
# MODE CONFIGURATION
# =============================================================================
# Set to "true" to use mock data for web search (search API keys not required)
# When enabled:
#   - Search mode will display "Search unavailable in demo mode" 
#   - Highlights mode will use pre-loaded mock health articles
#   - AI summaries/rewrites STILL WORK (LLM API keys still required)
# Perfect for assignment reviewers who don't have search API keys
# IMPORTANT: NEXT_PUBLIC_ prefix makes this visible to client-side code
NEXT_PUBLIC_USE_SYNTHETIC_DATA="true"
USE_SYNTHETIC_DATA="true"

# Set to "true" if you have search API keys configured below
# This flag enables the search UI (client-side needs this to show/hide search button)
NEXT_PUBLIC_SEARCH_AVAILABLE="false"

# =============================================================================
# AI/LLM PROVIDERS (REQUIRED - Choose one)
# =============================================================================

# Option 1: OpenAI (recommended, most reliable)
LLM_PROVIDER="openai"
OPENAI_API_KEY="your_openai_api_key_here"
OPENAI_LLM_MODEL="gpt-4o-mini"

# Option 2: OpenRouter (access to multiple free/paid models)
# LLM_PROVIDER="openrouter"
# OPENROUTER_API_KEY="your_openrouter_api_key_here"
# OPENROUTER_LLM_MODEL="openai/gpt-4o-mini"

# Option 3: Ollama (local, completely free, no API key needed)
# LLM_PROVIDER="ollama"
# OLLAMA_API_URL="http://localhost:11434"
# OLLAMA_FAST_MODEL="llama3.2"
# OLLAMA_QUALITY_MODEL="llama3.2:8b"

# =============================================================================
# SEARCH PROVIDERS (Optional if USE_SYNTHETIC_DATA="true")
# =============================================================================
# Only required for Search mode. Highlights mode works without these.

# Option 1: Tavily (recommended for health news search)
SEARCH_API_PROVIDER="tavily"
TAVILY_API_KEY="your_tavily_api_key_here"

# Option 2: Firecrawl (better for full article extraction)
# SEARCH_API_PROVIDER="firecrawl"
# FIRECRAWL_API_KEY="your_firecrawl_api_key_here"

# =============================================================================
# NOTES FOR ASSIGNMENT REVIEWERS
# =============================================================================
# Quick Start (No Search API Keys):
#   1. Set USE_SYNTHETIC_DATA="true"
#   2. Use any LLM provider (Ollama is free and local)
#   3. Run: npm install && npm run dev
#   4. Use "Highlights" mode only (Search mode will be disabled)
#
# Full Experience (With Search API Keys):
#   1. Set USE_SYNTHETIC_DATA="false"  
#   2. Add TAVILY_API_KEY or FIRECRAWL_API_KEY
#   3. Both Search and Highlights modes will work with real-time data

# =============================================================================
# REMOVED - NO LONGER USED IN HEALTH INFORMER
# =============================================================================
# The following were removed during cleanup from Narada AI:
# - VECTOR_DB_PROVIDER / QDRANT_* (vector database/RAG not needed)
# - EMBEDDING_PROVIDER / EMBEDDING_MODEL (embeddings not used)
# - RATE_LIMITING / UPSTASH_REDIS (not implemented)
# - COHERE_API_KEY (embedding provider removed)
# =============================================================================

# Upstash Redis (optional - for rate limiting)
# UPSTASH_REDIS_REST_URL=your_upstash_redis_url
# UPSTASH_REDIS_REST_TOKEN=your_upstash_redis_token

# =============================================================================
# PROVIDER CONFIGURATION
# =============================================================================

# Default providers (change these based on your preferences)
LLM_PROVIDER=openai
EMBEDDING_PROVIDER=openai
SEARCH_PROVIDER=tavily
VECTOR_DB_PROVIDER=qdrant

# =============================================================================
# NEXT.JS CONFIGURATION
# =============================================================================

NODE_ENV=production
NEXT_TELEMETRY_DISABLED=1
